{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ekang/anaconda2/lib/python2.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import iglob\n",
    "from keras.applications import VGG16, resnet50, xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.layers import ZeroPadding2D, Dense, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments for models\n",
    "\n",
    "### VGG16\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "            \n",
    "### resnet50\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "\n",
    "### xception\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(299, 299, 3)`.\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 71.\n",
    "            E.g. `(150, 150, 3)` would be one valid value.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Image to (224, 224, 3) for VGG16, and ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train/'\n",
    "TEST_DIR = 'data/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "NB_CLASSES = len(FISH_CLASSES)\n",
    "ROWS = 224  #720\n",
    "COLS = 224 #1280\n",
    "CHANNELS = 3\n",
    "\n",
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    # cv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    # bicubic interpolation is often chosen over bilinear interpolation or nearest neighbor in image resampling\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 photos of ALB\n",
      "200 photos of BET\n",
      "117 photos of DOL\n",
      "67 photos of LAG\n",
      "465 photos of NoF\n",
      "299 photos of OTHER\n",
      "176 photos of SHARK\n",
      "734 photos of YFT\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    \n",
    "    # Add elements to empty list\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    # repeat fish, len(fish_files) times\n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    \n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model\n",
    "\n",
    "### 1. Prepare Data to Correct Input\n",
    "### 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777"
     ]
    }
   ],
   "source": [
    "def vgg16_preprocess_from_img_path(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# uint8\tUnsigned integer (0 to 255)\n",
    "X_all = np.ndarray((len(files), CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files):\n",
    "    X_all[i] = vgg16_preprocess_from_img_path(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "# Categorical to Numerical\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = np_utils.to_categorical(y_all)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "# model_vgg16_conv.summary()\n",
    "\n",
    "#Create your own input format (here 3x200x200)\n",
    "input_shape = Input(shape=(CHANNELS,ROWS,COLS),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(input_shape)\n",
    "\n",
    "#Add the fully-connected layers with BatchNormalization and Dropout\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(NB_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "vgg16_model = Model(input=input_shape, output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # first: train only the top layers (which were randomly initialized)\n",
    "# # i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in model_vgg16_conv.layers:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "vgg16_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# checkpoint\n",
    "filepath = \"Vgg16 model and weights/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "history = vgg16_model.fit(X_train, y_train, batch_size=64, nb_epoch=50, validation_split=0.2, verbose=1, shuffle=True)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
